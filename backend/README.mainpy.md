# ğŸ“Œ AI Mesai AsistanÄ±

Bu proje, **FastAPI** tabanlÄ± bir yapay zekÃ¢ destekli backend uygulamasÄ±dÄ±r.  
AmaÃ§, Excel/CSVâ€™de tutulan **personel mesai verilerini** kullanarak doÄŸal dilde sorulan sorulara yanÄ±t vermektir.

Uygulama, **RAG (Retrieval-Augmented Generation)** mimarisi ile Ã§alÄ±ÅŸÄ±r:

1. KullanÄ±cÄ±nÄ±n sorusu embeddingâ€™e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r  
2. Qdrant vektÃ¶r veritabanÄ± Ã¼zerinden en alakalÄ± veriler bulunur   
3. Bu veriler LLaMA 3 modeline baÄŸlam olarak gÃ¶nderilir   
4. Modelden alÄ±nan yanÄ±t kullanÄ±cÄ±ya dÃ¶ndÃ¼rÃ¼lÃ¼r   

---

## ğŸš€ Ã–zellikler
- ğŸ–¥ï¸ FastAPI tabanlÄ± REST API  
- ğŸŒ TÃ¼rkÃ§e dil desteÄŸi  
- ğŸ”— SentenceTransformer (all-MiniLM-L6-v2) ile embedding Ã§Ä±karma  
- ğŸ’¾ Qdrant entegrasyonu ile vektÃ¶r arama  
- ğŸ¤– Ollama ile LLaMA 3 modeli Ã¼zerinden yanÄ±t Ã¼retme  
- ğŸ“Š DoÄŸru ve veri temelli hesaplamalar yapma  

---

## ğŸ“‚ Dosya AÃ§Ä±klamasÄ±

### ğŸ”¹ `main.py`
Projenin ana backend dosyasÄ±dÄ±r.

- `SoruModel`: APIâ€™ye gelen kullanÄ±cÄ± sorusunu temsil eden Pydantic modeli  
- `build_rag_prompt()`: KullanÄ±cÄ± sorusu + Qdrantâ€™tan gelen baÄŸlam ile LLaMA 3 iÃ§in Ã¶zel bir prompt oluÅŸturur  
- `/sor` endpointâ€™i:  
  - KullanÄ±cÄ±dan gelen soruyu iÅŸler  
  - Qdrant Ã¼zerinden baÄŸlam arar  
  - LLaMA 3 modelinden yanÄ±t Ã¼retir  

---

## âš™ï¸ Kurulum & Ã‡alÄ±ÅŸtÄ±rma

```bash
# Gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install -r requirements.txt

# APIâ€™yi baÅŸlatÄ±n
uvicorn main:app --reload